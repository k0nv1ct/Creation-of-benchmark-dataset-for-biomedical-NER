{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "your_project_id = 'numeric-ion-393603'\n",
    "your_location_id = 'us-central1'\n",
    "\n",
    "\n",
    "url = f\"https://healthcare.googleapis.com/v1beta1/projects/{your_project_id}/locations/{your_location_id}/services/nlp:analyzeEntities\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "import google.auth.transport.requests\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Path to your service account key file\n",
    "KEY_FILE = 'numeric-ion-393603-0d0575605119.json'\n",
    "\n",
    "# Load the credentials from the service account key file\n",
    "creds = service_account.Credentials.from_service_account_file(\n",
    "    KEY_FILE,\n",
    "    scopes=['https://www.googleapis.com/auth/cloud-platform']\n",
    ")\n",
    "\n",
    "# Create an HTTP authorized client using the credentials\n",
    "auth_request = google.auth.transport.requests.Request()\n",
    "creds.refresh(auth_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(row):\n",
    "    # Add the token to the headers\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json',\n",
    "        'Authorization': 'Bearer {}'.format(creds.token)\n",
    "        }\n",
    "    text = row\n",
    "    # Replace 'your_text' with the text you want to analyze\n",
    "    data = {\n",
    "        'documentContent': text\n",
    "        }\n",
    "    # Specify the API endpoint URL\n",
    "    your_project_id = 'numeric-ion-393603'\n",
    "    your_location_id = 'us-central1'\n",
    "    url = f\"https://healthcare.googleapis.com/v1beta1/projects/{your_project_id}/locations/{your_location_id}/services/nlp:analyzeEntities\"\n",
    "\n",
    "\n",
    "    # Make a POST request to the API endpoint\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    # Get JSON response\n",
    "    response_json = response.json()\n",
    "\n",
    "    return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>CASENO</th>\n",
       "      <th>NO</th>\n",
       "      <th>RECORD_SOURCE_TABLE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CLEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27187</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>31</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>10:45:54</td>\n",
       "      <td>53/ F \\n case of metastatic adenocarcinoma of ...</td>\n",
       "      <td>53/ f case of metastatic adenocarcinoma of lun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>27162</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>6</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>10:32:40</td>\n",
       "      <td>patient reviewd\\n\\nICD drain c/s: acenetobacte...</td>\n",
       "      <td>patient REVIEW ICD drain CULTURAL SENSITIVITY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>27186</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>30</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>11:46:54</td>\n",
       "      <td>ca adeno lung\\n\\ns/p M3 pem on 15/5/22\\n\\nc/o ...</td>\n",
       "      <td>CARCINOMA adeno lung s/p m3 pemetrexed on 15/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>27185</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>29</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>12:01:00</td>\n",
       "      <td>reviewed \\nUSG suspicous new lesion ? part of ...</td>\n",
       "      <td>reviewed ULTRASONOGRAPHY SUSPICIOUS new lesion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>27184</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>28</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>11:08:20</td>\n",
       "      <td>METATSTATIC ADENOCARCINOMA OF LUNG EGFR positi...</td>\n",
       "      <td>METASTATIC adenocarcinoma of lung egfr positiv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index    CASENO  NO RECORD_SOURCE_TABLE        DATE      TIME  \\\n",
       "0        0  27187  KD/11502  31    CLINICAL_REMARKS  2022-06-06  10:45:54   \n",
       "1       27  27162  KD/11502   6    CLINICAL_REMARKS  2021-11-10  10:32:40   \n",
       "2       29  27186  KD/11502  30    CLINICAL_REMARKS  2022-05-23  11:46:54   \n",
       "3       30  27185  KD/11502  29    CLINICAL_REMARKS  2022-05-13  12:01:00   \n",
       "4       31  27184  KD/11502  28    CLINICAL_REMARKS  2022-05-13  11:08:20   \n",
       "\n",
       "                                         DESCRIPTION  \\\n",
       "0  53/ F \\n case of metastatic adenocarcinoma of ...   \n",
       "1  patient reviewd\\n\\nICD drain c/s: acenetobacte...   \n",
       "2  ca adeno lung\\n\\ns/p M3 pem on 15/5/22\\n\\nc/o ...   \n",
       "3  reviewed \\nUSG suspicous new lesion ? part of ...   \n",
       "4  METATSTATIC ADENOCARCINOMA OF LUNG EGFR positi...   \n",
       "\n",
       "                                               CLEAN  \n",
       "0  53/ f case of metastatic adenocarcinoma of lun...  \n",
       "1  patient REVIEW ICD drain CULTURAL SENSITIVITY ...  \n",
       "2  CARCINOMA adeno lung s/p m3 pemetrexed on 15/5...  \n",
       "3  reviewed ULTRASONOGRAPHY SUSPICIOUS new lesion...  \n",
       "4  METASTATIC adenocarcinoma of lung egfr positiv...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('combined_clean-1.csv')\n",
    "df = df.sort_values(by=['CASENO'], ascending=False)\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASENO</th>\n",
       "      <th>NO</th>\n",
       "      <th>RECORD_SOURCE_TABLE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CLEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KD/11502</td>\n",
       "      <td>31</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>10:45:54</td>\n",
       "      <td>53/ F \\n case of metastatic adenocarcinoma of ...</td>\n",
       "      <td>53/ f case of metastatic adenocarcinoma of lun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KD/11502</td>\n",
       "      <td>6</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>10:32:40</td>\n",
       "      <td>patient reviewd\\n\\nICD drain c/s: acenetobacte...</td>\n",
       "      <td>patient REVIEW ICD drain CULTURAL SENSITIVITY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KD/11502</td>\n",
       "      <td>30</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>11:46:54</td>\n",
       "      <td>ca adeno lung\\n\\ns/p M3 pem on 15/5/22\\n\\nc/o ...</td>\n",
       "      <td>CARCINOMA adeno lung s/p m3 pemetrexed on 15/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KD/11502</td>\n",
       "      <td>29</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>12:01:00</td>\n",
       "      <td>reviewed \\nUSG suspicous new lesion ? part of ...</td>\n",
       "      <td>reviewed ULTRASONOGRAPHY SUSPICIOUS new lesion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KD/11502</td>\n",
       "      <td>28</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>11:08:20</td>\n",
       "      <td>METATSTATIC ADENOCARCINOMA OF LUNG EGFR positi...</td>\n",
       "      <td>METASTATIC adenocarcinoma of lung egfr positiv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CASENO  NO RECORD_SOURCE_TABLE        DATE      TIME  \\\n",
       "0  KD/11502  31    CLINICAL_REMARKS  2022-06-06  10:45:54   \n",
       "1  KD/11502   6    CLINICAL_REMARKS  2021-11-10  10:32:40   \n",
       "2  KD/11502  30    CLINICAL_REMARKS  2022-05-23  11:46:54   \n",
       "3  KD/11502  29    CLINICAL_REMARKS  2022-05-13  12:01:00   \n",
       "4  KD/11502  28    CLINICAL_REMARKS  2022-05-13  11:08:20   \n",
       "\n",
       "                                         DESCRIPTION  \\\n",
       "0  53/ F \\n case of metastatic adenocarcinoma of ...   \n",
       "1  patient reviewd\\n\\nICD drain c/s: acenetobacte...   \n",
       "2  ca adeno lung\\n\\ns/p M3 pem on 15/5/22\\n\\nc/o ...   \n",
       "3  reviewed \\nUSG suspicous new lesion ? part of ...   \n",
       "4  METATSTATIC ADENOCARCINOMA OF LUNG EGFR positi...   \n",
       "\n",
       "                                               CLEAN  \n",
       "0  53/ f case of metastatic adenocarcinoma of lun...  \n",
       "1  patient REVIEW ICD drain CULTURAL SENSITIVITY ...  \n",
       "2  CARCINOMA adeno lung s/p m3 pemetrexed on 15/5...  \n",
       "3  reviewed ULTRASONOGRAPHY SUSPICIOUS new lesion...  \n",
       "4  METASTATIC adenocarcinoma of lung egfr positiv...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['index','level_0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>CASENO</th>\n",
       "      <th>NO</th>\n",
       "      <th>RECORD_SOURCE_TABLE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CLEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>31</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>10:45:54</td>\n",
       "      <td>53/ F \\n case of metastatic adenocarcinoma of ...</td>\n",
       "      <td>53/ f case of metastatic adenocarcinoma of lun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>6</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2021-11-10</td>\n",
       "      <td>10:32:40</td>\n",
       "      <td>patient reviewd\\n\\nICD drain c/s: acenetobacte...</td>\n",
       "      <td>patient REVIEW ICD drain CULTURAL SENSITIVITY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>30</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-05-23</td>\n",
       "      <td>11:46:54</td>\n",
       "      <td>ca adeno lung\\n\\ns/p M3 pem on 15/5/22\\n\\nc/o ...</td>\n",
       "      <td>CARCINOMA adeno lung s/p m3 pemetrexed on 15/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>29</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>12:01:00</td>\n",
       "      <td>reviewed \\nUSG suspicous new lesion ? part of ...</td>\n",
       "      <td>reviewed ULTRASONOGRAPHY SUSPICIOUS new lesion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>KD/11502</td>\n",
       "      <td>28</td>\n",
       "      <td>CLINICAL_REMARKS</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>11:08:20</td>\n",
       "      <td>METATSTATIC ADENOCARCINOMA OF LUNG EGFR positi...</td>\n",
       "      <td>METASTATIC adenocarcinoma of lung egfr positiv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    CASENO  NO RECORD_SOURCE_TABLE        DATE      TIME  \\\n",
       "0      0  KD/11502  31    CLINICAL_REMARKS  2022-06-06  10:45:54   \n",
       "1      1  KD/11502   6    CLINICAL_REMARKS  2021-11-10  10:32:40   \n",
       "2      2  KD/11502  30    CLINICAL_REMARKS  2022-05-23  11:46:54   \n",
       "3      3  KD/11502  29    CLINICAL_REMARKS  2022-05-13  12:01:00   \n",
       "4      4  KD/11502  28    CLINICAL_REMARKS  2022-05-13  11:08:20   \n",
       "\n",
       "                                         DESCRIPTION  \\\n",
       "0  53/ F \\n case of metastatic adenocarcinoma of ...   \n",
       "1  patient reviewd\\n\\nICD drain c/s: acenetobacte...   \n",
       "2  ca adeno lung\\n\\ns/p M3 pem on 15/5/22\\n\\nc/o ...   \n",
       "3  reviewed \\nUSG suspicous new lesion ? part of ...   \n",
       "4  METATSTATIC ADENOCARCINOMA OF LUNG EGFR positi...   \n",
       "\n",
       "                                               CLEAN  \n",
       "0  53/ f case of metastatic adenocarcinoma of lun...  \n",
       "1  patient REVIEW ICD drain CULTURAL SENSITIVITY ...  \n",
       "2  CARCINOMA adeno lung s/p m3 pemetrexed on 15/5...  \n",
       "3  reviewed ULTRASONOGRAPHY SUSPICIOUS new lesion...  \n",
       "4  METASTATIC adenocarcinoma of lung egfr positiv...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['KD/11502', 'KB/54453', 'GH/02748', 'GH/01825', 'GG/02614',\n",
      "       'CV/61532', 'CV/42224', 'CV/39040', 'CV/38588', 'CV/35737'],\n",
      "      dtype=object), array(['CV/35455', 'CV/34743', 'CV/34601', 'CV/34213', 'CV/33233',\n",
      "       'CV/33125', 'CV/32504', 'CV/30939', 'CV/29466', 'CV/28982'],\n",
      "      dtype=object), array(['CV/27372', 'CV/27101', 'CV/27096', 'CV/27053', 'CV/26695',\n",
      "       'CV/25374', 'CV/25321', 'CV/25088', 'CV/24260', 'CV/23117'],\n",
      "      dtype=object), array(['CV/21899', 'CV/21285', 'CV/21195', 'CV/21022', 'CV/20419',\n",
      "       'CV/20325', 'CV/20261', 'CV/20084', 'CV/19310', 'CV/18857'],\n",
      "      dtype=object), array(['CV/18752', 'CV/18124', 'CV/18116', 'CV/18068', 'CV/17365',\n",
      "       'CV/17298', 'CV/17187', 'CV/17160', 'CV/16838', 'CV/16820'],\n",
      "      dtype=object), array(['CV/16716', 'CV/16710', 'CV/16587', 'CV/16550', 'CV/16391',\n",
      "       'CV/15886', 'CV/15877', 'CV/15732', 'CV/15589', 'CV/15586'],\n",
      "      dtype=object), array(['CV/15565', 'CV/15562', 'CV/15474', 'CV/15222', 'CV/15151',\n",
      "       'CV/14472', 'CV/14469', 'CV/14388', 'CV/14367', 'CV/14271'],\n",
      "      dtype=object), array(['CV/14189', 'CV/14181', 'CV/14178', 'CV/14163', 'CV/14140',\n",
      "       'CV/14135', 'CV/14133', 'CV/14132', 'CV/14058', 'CV/13787'],\n",
      "      dtype=object), array(['CV/13770', 'CV/13717', 'CV/13707', 'CV/13704', 'CV/13603',\n",
      "       'CV/13521', 'CV/13493', 'CV/13368', 'CV/13280', 'CV/13249'],\n",
      "      dtype=object), array(['CV/13241', 'CV/13165', 'CV/13091', 'CV/13050', 'CV/13041',\n",
      "       'CV/12928', 'CV/12815', 'CV/12749', 'CV/12721', 'CV/12715'],\n",
      "      dtype=object), array(['CV/12711', 'CV/12623', 'CV/12574', 'CV/12555', 'CV/11942',\n",
      "       'CV/11447', 'CV/11379', 'CV/11344', 'CV/11340', 'CV/11329'],\n",
      "      dtype=object), array(['CV/11239', 'CV/11205', 'CV/11189', 'CV/11049', 'CV/11019',\n",
      "       'CV/11007', 'CV/10999', 'CV/10970', 'CV/10968', 'CV/10960'],\n",
      "      dtype=object), array(['CV/10826', 'CV/10772', 'CV/10608', 'CV/10534', 'CV/10519',\n",
      "       'CV/10512', 'CV/10442', 'CV/10405', 'CV/10208', 'CV/10075'],\n",
      "      dtype=object), array(['CV/10001', 'CV/09439', 'CV/09395', 'CV/09388', 'CV/09348',\n",
      "       'CV/09347', 'CV/09315', 'CV/09241', 'CV/09135', 'CV/09083'],\n",
      "      dtype=object), array(['CV/09051', 'CV/08957', 'CV/08949', 'CV/08944', 'CV/08841',\n",
      "       'CV/08828', 'CV/08787', 'CV/08766', 'CV/08704', 'CV/08693'],\n",
      "      dtype=object), array(['CV/08657', 'CV/08618', 'CV/08597', 'CV/08587', 'CV/08586',\n",
      "       'CV/08557', 'CV/08508', 'CV/08373', 'CV/08221', 'CV/08212'],\n",
      "      dtype=object), array(['CV/08193', 'CV/08018', 'CV/08010', 'CV/07586', 'CV/06918',\n",
      "       'CV/06914', 'CV/06913', 'CV/06895', 'CV/06886', 'CV/06769'],\n",
      "      dtype=object), array(['CV/06740', 'CV/06698', 'CV/06682', 'CV/06650', 'CV/06588',\n",
      "       'CV/06582', 'CV/06490 ', 'CV/06490', 'CV/06471', 'CV/06465'],\n",
      "      dtype=object), array(['CV/06408', 'CV/06366', 'CV/06363', 'CV/06349', 'CV/06322',\n",
      "       'CV/06306', 'CV/06287', 'CV/06276', 'CV/06166', 'CV/06101'],\n",
      "      dtype=object), array(['CV/06059', 'CV/06041', 'CV/06003', 'CV/05997', 'CV/05976',\n",
      "       'CV/05964', 'CV/05882', 'CV/05878', 'CV/05870', 'CV/05868'],\n",
      "      dtype=object), array(['CV/05843', 'CV/05781', 'CV/05724', 'CV/05656', 'CV/05603',\n",
      "       'CV/05573', 'CV/05561', 'CV/05559', 'CV/05534', 'CV/05523'],\n",
      "      dtype=object), array(['CV/05522', 'CV/05502', 'CV/05500', 'CV/05486', 'CV/05468',\n",
      "       'CV/05435', 'CV/05433', 'CV/05431', 'CV/05430', 'CV/05417'],\n",
      "      dtype=object), array(['CV/05407', 'CV/05360', 'CV/05298', 'CV/05285', 'CV/05263',\n",
      "       'CV/05244', 'CV/05233', 'CV/05229', 'CV/05187', 'CV/05172'],\n",
      "      dtype=object), array(['CV/05143', 'CV/05067', 'CV/05051', 'CV/04956', 'CV/04906',\n",
      "       'CV/04888', 'CV/04875', 'CV/04846', 'CV/04806', 'CV/04797'],\n",
      "      dtype=object), array(['CV/04777', 'CV/04772', 'CV/04766', 'CV/04738', 'CV/04695',\n",
      "       'CV/04693', 'CV/04659', 'CV/04647', 'CV/04641', 'CV/04639'],\n",
      "      dtype=object), array(['CV/04623', 'CV/04603', 'CV/04575', 'CV/04523', 'CV/04508',\n",
      "       'CV/04469', 'CV/04466', 'CV/04451', 'CV/04421', 'CV/04320'],\n",
      "      dtype=object), array(['CV/04307', 'CV/04286', 'CV/04264', 'CV/04224', 'CV/04211',\n",
      "       'CV/04181', 'CV/04135', 'CV/04064', 'CV/04061', 'CV/04042'],\n",
      "      dtype=object), array(['CV/04016', 'CV/04006', 'CV/03619', 'CV/03496', 'CV/03475',\n",
      "       'CV/03447', 'CV/03401', 'CV/03360', 'CV/03358', 'CV/03305'],\n",
      "      dtype=object), array(['CV/03303', 'CV/03279', 'CV/03270', 'CV/03204', 'CV/03203',\n",
      "       'CV/03175', 'CV/03172', 'CV/03153', 'CV/03147', 'CV/03140'],\n",
      "      dtype=object), array(['CV/03135', 'CV/03118', 'CV/03108', 'CV/03102', 'CV/03082',\n",
      "       'CV/03028', 'CV/02980', 'CV/02970', 'CV/02964', 'CV/02923'],\n",
      "      dtype=object), array(['CV/02913', 'CV/02898', 'CV/02865', 'CV/02857', 'CV/02842',\n",
      "       'CV/02834', 'CV/02832', 'CV/02826', 'CV/02825', 'CV/02796'],\n",
      "      dtype=object), array(['CV/02792', 'CV/02707', 'CV/02688', 'CV/02673', 'CV/02632',\n",
      "       'CV/02618', 'CV/02615', 'CV/02569', 'CV/02537', 'CV/02492'],\n",
      "      dtype=object), array(['CV/02488', 'CV/02485', 'CV/02480', 'CV/02470', 'CV/02424',\n",
      "       'CV/02267', 'CV/02234', 'CV/02225', 'CV/02158', 'CV/02048'],\n",
      "      dtype=object), array(['CV/02034', 'CV/01747', 'CV/01518', 'CV/01380', 'CV/01208',\n",
      "       'CV/01200', 'CV/01141', 'CV/00995', 'CV/00987', 'CV/00978'],\n",
      "      dtype=object), array(['CV/00976', 'CV/00975', 'CV/00966', 'CV/00945', 'CV/00868',\n",
      "       'CV/00841', 'CV/00831', 'CV/00786', 'CV/00781', 'CV/00730'],\n",
      "      dtype=object), array(['CV/00613', 'CV/00607', 'CV/00554', 'CV/00553', 'CV/00545',\n",
      "       'CV/00510', 'CV/00507', 'CV/00464', 'CV/00456', 'CV/00454'],\n",
      "      dtype=object), array(['CV/00439', 'CV/00434', 'CV/00412', 'CV/00395', 'CV/00311',\n",
      "       'CV/00304', 'CV/00287', 'CV/00259', 'CV/00228', 'CV/00169'],\n",
      "      dtype=object), array(['CV/00110', 'CV/00094', 'CV/00065', 'CV/00061', 'CV/00042',\n",
      "       'CV/00040', 'CV/00012', 'CU/51900', 'CU/35575', 'CU/35207'],\n",
      "      dtype=object), array(['CU/35195', 'CU/35177', 'CU/35136', 'CU/35080', 'CU/35042',\n",
      "       'CU/34963', 'CU/34912', 'CU/34882', 'CU/34872', 'CU/34850'],\n",
      "      dtype=object), array(['CU/34833', 'CU/34808', 'CU/34805', 'CU/34785', 'CU/34738',\n",
      "       'CU/34704', 'CU/34698', 'CU/34694', 'CU/34686', 'CU/34665'],\n",
      "      dtype=object), array(['CU/34662', 'CU/34654', 'CU/34650', 'CU/34515', 'CU/34507',\n",
      "       'CU/34505', 'CU/34433', 'CU/34428', 'CU/34385', 'CU/34320'],\n",
      "      dtype=object), array(['CU/34300', 'CU/34278', 'CU/34260', 'CU/34245', 'CU/34206',\n",
      "       'CU/34175', 'CU/34170', 'CU/34160', 'CU/34157', 'CU/34133'],\n",
      "      dtype=object), array(['CU/34125', 'CU/34115', 'CU/34109', 'CU/34105', 'CU/34103',\n",
      "       'CU/33989', 'CU/33987', 'CU/33982', 'CU/33973', 'CU/33966'],\n",
      "      dtype=object), array(['CU/33940', 'CU/33935', 'CU/33932', 'CU/33931', 'CU/33928',\n",
      "       'CU/33871', 'CU/33831', 'CU/33813', 'CU/33797', 'CU/33734'],\n",
      "      dtype=object), array(['CU/33710', 'CU/33607', 'CU/33543', 'CU/33497', 'CU/33473',\n",
      "       'CU/33430', 'CU/33426', 'CU/33396', 'CU/33390', 'CU/33387'],\n",
      "      dtype=object), array(['CU/33339', 'CU/33330', 'CU/33303', 'CU/33288', 'CU/33246',\n",
      "       'CU/33222', 'CU/33206', 'CU/33181', 'CU/33174', 'CU/33155'],\n",
      "      dtype=object), array(['CU/33096', 'CU/33080', 'CU/33078', 'CU/33058', 'CU/33027',\n",
      "       'CU/33022', 'CU/33010', 'CU/33007', 'CU/32958', 'CU/32940'],\n",
      "      dtype=object), array(['CU/32819', 'CU/32801', 'CU/32785', 'CU/32782', 'CU/32767',\n",
      "       'CU/32712', 'CU/32691', 'CU/32678', 'CU/32673', 'CU/32062'],\n",
      "      dtype=object), array(['CU/31889', 'CU/31574', 'CU/31568', 'CU/31553', 'CU/31541',\n",
      "       'CU/31531', 'CU/31522', 'CU/31431', 'CU/31429', 'CU/31394'],\n",
      "      dtype=object), array(['CU/31236', 'CU/31154', 'CU/31149', 'CU/31132', 'CU/31120',\n",
      "       'CU/31110', 'CU/31096', 'CU/30984', 'CU/30970', 'CU/30957'],\n",
      "      dtype=object), array(['CU/30916', 'CU/30906', 'CU/30896', 'CU/30873', 'CU/30861',\n",
      "       'CU/30844', 'CU/30813', 'CU/30738', 'CU/30698', 'CU/30680'],\n",
      "      dtype=object), array(['CU/30623', 'CU/30614', 'CU/30594', 'CU/30587', 'CU/30551',\n",
      "       'CU/30533', 'CU/30528', 'CU/30517', 'CU/30465', 'CU/30441'],\n",
      "      dtype=object), array(['CU/30408', 'CU/30371', 'CU/30346', 'CU/30342', 'CU/30337',\n",
      "       'CU/30330', 'CU/30320', 'CU/30314', 'CU/30298', 'CU/30297'],\n",
      "      dtype=object), array(['CU/30287', 'CU/30267', 'CU/30265', 'CU/30262', 'CU/30246',\n",
      "       'CU/30240', 'CU/30197', 'CU/30193', 'CU/30160', 'CU/30137'],\n",
      "      dtype=object), array(['CU/30132', 'CU/30115', 'CU/30074', 'CU/30051', 'CU/30045',\n",
      "       'CU/30031', 'CU/30001', 'CU/29051', 'CU/29030', 'CU/29026'],\n",
      "      dtype=object), array(['CU/29013', 'CU/29012', 'CU/28874', 'CU/28847', 'CU/28764',\n",
      "       'CU/28755', 'CU/28751', 'CU/28733', 'CU/28683', 'CU/28681'],\n",
      "      dtype=object), array(['CU/28666', 'CU/28662', 'CU/28653', 'CU/28624', 'CU/28604',\n",
      "       'CU/28580', 'CU/28562', 'CU/28518', 'CU/28415', 'CU/28412'],\n",
      "      dtype=object), array(['CU/28384', 'CU/28380', 'CU/28362', 'CU/28345', 'CU/28340',\n",
      "       'CU/28335', 'CU/28330', 'CU/28267', 'CU/28243', 'CU/28242'],\n",
      "      dtype=object), array(['CU/28212', 'CU/28198', 'CU/28186', 'CU/28153', 'CU/28074',\n",
      "       'CU/28032', 'CU/27965', 'CU/27956', 'CU/27891', 'CU/27853'],\n",
      "      dtype=object), array(['CU/27834', 'CU/27748', 'CU/27727', 'CU/27640', 'CU/27632',\n",
      "       'CU/27623', 'CU/27616', 'CU/27608', 'CU/27603', 'CU/27601'],\n",
      "      dtype=object), array(['CU/27596', 'CU/27583', 'CU/27580', 'CU/27553', 'CU/27510',\n",
      "       'CU/27499', 'CU/27480', 'CU/27471', 'CU/27416', 'CU/27362'],\n",
      "      dtype=object), array(['CU/27333', 'CU/27328', 'CU/27322', 'CU/27290', 'CU/27240',\n",
      "       'CU/27239', 'CU/27228', 'CU/27213', 'CU/27188', 'CU/27185'],\n",
      "      dtype=object), array(['CU/27128', 'CU/27104', 'CU/27103', 'CU/27062', 'CU/27047',\n",
      "       'CU/27029', 'CU/27011', 'CU/26987', 'CU/26924', 'CU/26844'],\n",
      "      dtype=object), array(['CU/26834', 'CU/26816', 'CU/26796', 'CU/26795', 'CU/26780',\n",
      "       'CU/26759', 'CU/26740', 'CU/26732', 'CU/26718', 'CU/26717'],\n",
      "      dtype=object), array(['CU/26704', 'CU/26655', 'CU/26638', 'CU/26544', 'CU/26514',\n",
      "       'CU/26487', 'CU/26139', 'CU/25826', 'CU/25731', 'CU/25547'],\n",
      "      dtype=object), array(['CU/25529', 'CU/25510', 'CU/25481', 'CU/25417', 'CU/25406',\n",
      "       'CU/25383', 'CU/25377', 'CU/25366', 'CU/25321', 'CU/25303'],\n",
      "      dtype=object), array(['CU/25278', 'CU/25266', 'CU/25264', 'CU/25262', 'CU/25255',\n",
      "       'CU/25239', 'CU/25236', 'CU/25225', 'CU/25221', 'CU/25160'],\n",
      "      dtype=object), array(['CU/25119', 'CU/25103', 'CU/25099', 'CU/25070', 'CU/24955',\n",
      "       'CU/24953', 'CU/24940', 'CU/24929', 'CU/24928', 'CU/24897'],\n",
      "      dtype=object), array(['CU/24896', 'CU/24820', 'CU/24808', 'CU/24801', 'CU/24797',\n",
      "       'CU/24795', 'CU/24765', 'CU/24746', 'CU/24704', 'CU/24683'],\n",
      "      dtype=object), array(['CU/24676', 'CU/24664', 'CU/24655', 'CU/24653', 'CU/24649',\n",
      "       'CU/24622', 'CU/24616', 'CU/24606', 'CU/24589', 'CU/24586'],\n",
      "      dtype=object), array(['CU/24579', 'CU/24562', 'CU/24547', 'CU/24542', 'CU/24491',\n",
      "       'CU/24472', 'CU/24460', 'CU/24458', 'CU/24449', 'CU/24435'],\n",
      "      dtype=object), array(['CU/24427', 'CU/24423', 'CU/24421', 'CU/24371', 'CU/24328',\n",
      "       'CU/24289', 'CU/24282', 'CU/24217', 'CU/24203', 'CU/24145'],\n",
      "      dtype=object), array(['CU/24134', 'CU/24124', 'CU/24120', 'CU/24102', 'CU/24074',\n",
      "       'CU/24066', 'CU/24064', 'CU/24061', 'CU/24058', 'CU/24053'],\n",
      "      dtype=object), array(['CU/24047', 'CU/24013', 'CU/23928', 'CU/23914', 'CU/23909',\n",
      "       'CU/23885', 'CU/23811', 'CU/23808', 'CU/23798', 'CU/23769'],\n",
      "      dtype=object), array(['CU/23765', 'CU/23738', 'CU/23726', 'CU/23724', 'CU/23713',\n",
      "       'CU/23672', 'CU/23654', 'CU/23614', 'CU/23612', 'CU/23531'],\n",
      "      dtype=object), array(['CU/23524', 'CU/23490', 'CU/23488', 'CU/23445', 'CU/23434',\n",
      "       'CU/23376', 'CU/23291', 'CU/23266', 'CU/23245', 'CU/23205'],\n",
      "      dtype=object), array(['CU/23197', 'CU/23188', 'CU/23183', 'CU/23180', 'CU/23167',\n",
      "       'CU/23165', 'CU/23155', 'CU/23146', 'CU/23138', 'CU/23082'],\n",
      "      dtype=object), array(['CU/23043', 'CU/23004', 'CU/22988', 'CU/22922', 'CU/22908',\n",
      "       'CU/22884', 'CU/22877', 'CU/22874', 'CU/22844', 'CU/22798'],\n",
      "      dtype=object), array(['CU/22720', 'CU/22668', 'CU/22532', 'CU/22139', 'CU/21997',\n",
      "       'CU/21989', 'CU/21930', 'CU/21909', 'CU/21897', 'CU/21862'],\n",
      "      dtype=object), array(['CU/21821', 'CU/21807', 'CU/21794', 'CU/21740', 'CU/21739',\n",
      "       'CU/21678', 'CU/21677', 'CU/21571', 'CU/21565', 'CU/21534'],\n",
      "      dtype=object), array(['CU/21508', 'CU/21471', 'CU/21451', 'CU/21418', 'CU/21407',\n",
      "       'CU/21276', 'CU/21248', 'CU/21233', 'CU/21160', 'CU/21128'],\n",
      "      dtype=object), array(['CU/21113', 'CU/21109', 'CU/21078', 'CU/20987', 'CU/20906',\n",
      "       'CU/20889', 'CU/20822', 'CU/20681', 'CU/20659', 'CU/19938'],\n",
      "      dtype=object), array(['CU/19886', 'CU/19851', 'CU/19742', 'CU/19706', 'CU/19686',\n",
      "       'CU/19677', 'CU/19675', 'CU/19668', 'CU/19610', 'CU/18992'],\n",
      "      dtype=object), array(['CU/18783', 'CU/18644', 'CU/18484', 'CU/18416', 'CU/18382',\n",
      "       'CU/17818', 'CU/17752', 'CU/17690', 'CU/16362', 'CU/15822'],\n",
      "      dtype=object), array(['CU/15807', 'CU/15460', 'CU/15445', 'CU/15167', 'CU/15088',\n",
      "       'CU/14723', 'CU/14200', 'CU/13051', 'CU/12063', 'CU/11407'],\n",
      "      dtype=object), array(['CU/11317', 'CU/09782', 'CU/08917', 'CU/07608', 'CU/03062',\n",
      "       'CU/02177', 'CT/08579', 'CT/05092', 'CR/33198', 'CN/06164'],\n",
      "      dtype=object), array(['CK/16456', 'CH/06243', 'BS/00816', '18F2023/003297',\n",
      "       '11F2023/016069', '11F2023/015321', '11F2023/014656',\n",
      "       '11F2023/013483', '11F2023/012170', '11F2023/010755'], dtype=object), array(['11F2023/009386', '11F2023/002613'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "#make lists with 10 case numbers each\n",
    "cases = df['CASENO'].unique()\n",
    "# Calculate the number of lists needed\n",
    "num_lists = int(np.ceil(len(cases) / 10))\n",
    "\n",
    "# Create a list of lists\n",
    "lists_of_cases = [cases[i * 10 : (i + 1) * 10] for i in range(num_lists)]\n",
    "\n",
    "print(lists_of_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def struct_entities(df):\n",
    "  data = {}\n",
    "  source = []\n",
    "  caseno = []\n",
    "  noteno = []\n",
    "  date = []\n",
    "  desc = []\n",
    "  temp_conf = []\n",
    "  temp_asst = []\n",
    "  cert_asst = []\n",
    "  cert_conf = []\n",
    "  subject = []\n",
    "  linked_entity_id = []\n",
    "  linked_to_id = []\n",
    "  linked_from_id = []\n",
    "  linked_from_text = []\n",
    "  linked_to_text = []\n",
    "  related_entities = []\n",
    "  related_from_id = []\n",
    "  related_to_id = []\n",
    "  related_from_text = []\n",
    "  related_to_text = []\n",
    "  mention_ids = []  # List to store mention IDs\n",
    "  entity_types = []  # List to store entity types\n",
    "  texts = []  # List to store texts\n",
    "  confi = []\n",
    "  # Assuming you have already extracted the relevant data in the following lists\n",
    "  mention_ids = []  # List to store mention IDs\n",
    "  entity_types = []  # List to store entity types\n",
    "  texts = []  # List to store texts\n",
    "\n",
    "  for i in range(len(df)):\n",
    "    if isinstance(df['NER'][i], str):\n",
    "      x = ast.literal_eval(df['NER'][i])\n",
    "    else:\n",
    "      x = df['NER'][i]\n",
    "\n",
    "\n",
    "    if 'entityMentions' in x:\n",
    "        for entity in x['entityMentions']:\n",
    "            id = f\"[id - {entity['mentionId']}]\"\n",
    "            entity_type = f\"[entity-type = {entity['type']}]\"\n",
    "            text = f\"[text = {entity['text']['content']}]\"\n",
    "\n",
    "            mention_ids.append(entity['mentionId'])\n",
    "            entity_types.append(entity['type'])\n",
    "            texts.append(entity['text']['content'])\n",
    "            confi.append(entity['confidence'])\n",
    "            \n",
    "            if 'temporalAssessment' in entity:\n",
    "              temp_asst.append(entity['temporalAssessment']['value'])\n",
    "              temp_conf.append(entity['temporalAssessment']['confidence'])\n",
    "            else:\n",
    "              temp_asst.append(None)\n",
    "            if 'certaintyAssessment' in entity:\n",
    "              cert_asst.append(entity['certaintyAssessment']['value'])\n",
    "              cert_conf.append(entity['certaintyAssessment']['confidence'])\n",
    "            else:\n",
    "              cert_asst.append(None)\n",
    "\n",
    "            if 'subject' in entity:\n",
    "              subject.append(entity['subject']['value'])\n",
    "            else:\n",
    "              subject.append(None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    linked_entity_id = []\n",
    "    if 'entityMentions' in x:\n",
    "        for entity in x['entityMentions']:\n",
    "          if 'linkedEntities' in entity:\n",
    "            id = entity['mentionId']\n",
    "            text = entity['text']['content']\n",
    "            linked_id = entity['linkedEntities']\n",
    "            for ids in linked_id:\n",
    "              linked_entity_id.append([id,text,ids['entityId']])\n",
    "\n",
    "    linked_entities = []\n",
    "    if len(linked_entity_id) != 0:\n",
    "        for ids in linked_entity_id:\n",
    "          id = ids[0]\n",
    "          entity_id = ids[2]\n",
    "          text = ids[1]\n",
    "          for entities in x['entities']:\n",
    "              if entities['entityId'] == entity_id:\n",
    "                term = entities['preferredTerm']\n",
    "                linked_entities.append([id,text,term,entity_id])\n",
    "                linked_from_id.append(id)\n",
    "                linked_from_text.append(text)\n",
    "                linked_to_id.append(entity_id)\n",
    "                linked_to_text.append(term)\n",
    "\n",
    "    for k in range(len(mention_ids)):\n",
    "      caseno.append(df['CASENO'][i])\n",
    "      date.append(df['DATE'][i])\n",
    "      desc.append(df['DESCRIPTION'][i])\n",
    "      source.append(df['RECORD_SOURCE_TABLE'][i])\n",
    "      noteno.append(df['index'][i])\n",
    "\n",
    "\n",
    "    related_entities = []\n",
    "    if 'relationships' in x:\n",
    "        for relations in x['relationships']:\n",
    "          related_entities.append([relations['subjectId'],relations['objectId']])\n",
    "\n",
    "\n",
    "    relationship = []\n",
    "    if len(related_entities) != 0:\n",
    "        relationship = []\n",
    "        for ids in related_entities:\n",
    "            id1 = ids[0]\n",
    "            id2 = ids[1]\n",
    "            text1 = None  # Initialize text1\n",
    "            text2 = None  # Initialize text2\n",
    "            for entity in x['entityMentions']:\n",
    "                if entity['mentionId'] == str(id1):\n",
    "                    text1 = entity['text']['content']\n",
    "                if entity['mentionId'] == str(id2):\n",
    "                    text2 = entity['text']['content']\n",
    "\n",
    "            relationship.append([id1, text1, \"related to\", id2, text2])\n",
    "            related_from_id.append(id1)\n",
    "            related_from_text.append(text1)\n",
    "            related_to_id.append(id2)\n",
    "            related_to_text.append(text2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data.update({\n",
    "              'CASE NO': caseno,\n",
    "              'NOTE NO':noteno,\n",
    "              'DATE': date,\n",
    "              'SOURCE':source,\n",
    "              'Entity id': mention_ids,\n",
    "              'entity_type': entity_types,\n",
    "              'text in DESC': texts,\n",
    "              'confidence':confi,\n",
    "              'Temporal Assesment':temp_asst,\n",
    "              'Temporal Confidence':temp_conf,\n",
    "              'Certainity Assesment':cert_asst,\n",
    "              'Certainity Confidence':cert_conf,\n",
    "              'Subject':subject\n",
    "              })\n",
    "\n",
    "\n",
    "\n",
    "  return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get linked entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def struct_linked_entities(df):\n",
    "  data = {}\n",
    "  caseno = []\n",
    "  noteno = []\n",
    "  date = []\n",
    "  desc = []\n",
    "  source = []\n",
    "  temp_asst = []\n",
    "  cert_asst = []\n",
    "  subject = []\n",
    "  linked_entity_id = []\n",
    "  linked_to_id = []\n",
    "  linked_from_id = []\n",
    "  linked_from_text = []\n",
    "  linked_to_text = []\n",
    "  related_entities = []\n",
    "  related_from_id = []\n",
    "  related_to_id = []\n",
    "  related_from_text = []\n",
    "  related_to_text = []\n",
    "  mention_ids = []  # List to store mention IDs\n",
    "  entity_types = []  # List to store entity types\n",
    "  texts = []  # List to store texts\n",
    "  confi = []\n",
    "  # Assuming you have already extracted the relevant data in the following lists\n",
    "  mention_ids = []  # List to store mention IDs\n",
    "  entity_types = []  # List to store entity types\n",
    "  texts = []  # List to store texts\n",
    "\n",
    "  for i in range(len(df)):\n",
    "    if isinstance(df['NER'][i], str):\n",
    "      x = ast.literal_eval(df['NER'][i])\n",
    "    else:\n",
    "      x = df['NER'][i]\n",
    "\n",
    "\n",
    "    if 'entityMentions' in x:\n",
    "        for entity in x['entityMentions']:\n",
    "            id = f\"[id - {entity['mentionId']}]\"\n",
    "            entity_type = f\"[entity-type = {entity['type']}]\"\n",
    "            text = f\"[text = {entity['text']['content']}]\"\n",
    "\n",
    "            mention_ids.append(entity['mentionId'])\n",
    "            entity_types.append(entity['type'])\n",
    "            texts.append(entity['text']['content'])\n",
    "            confi.append(entity['confidence'])\n",
    "            if 'temporalAssessment' in entity:\n",
    "              temp_asst.append(entity['temporalAssessment']['value'])\n",
    "            else:\n",
    "              temp_asst.append(None)\n",
    "            if 'certaintyAssessment' in entity:\n",
    "              cert_asst.append(entity['certaintyAssessment']['value'])\n",
    "            else:\n",
    "              cert_asst.append(None)\n",
    "\n",
    "            if 'subject' in entity:\n",
    "              subject.append(entity['subject']['value'])\n",
    "            else:\n",
    "              subject.append(None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    linked_entity_id = []\n",
    "    if 'entityMentions' in x:\n",
    "        for entity in x['entityMentions']:\n",
    "          if 'linkedEntities' in entity:\n",
    "            id = entity['mentionId']\n",
    "            text = entity['text']['content']\n",
    "            linked_id = entity['linkedEntities']\n",
    "            for ids in linked_id:\n",
    "              linked_entity_id.append([id,text,ids['entityId']])\n",
    "\n",
    "    linked_entities = []\n",
    "    if len(linked_entity_id) != 0:\n",
    "        for ids in linked_entity_id:\n",
    "          id = ids[0]\n",
    "          entity_id = ids[2]\n",
    "          text = ids[1]\n",
    "          for entities in x['entities']:\n",
    "              if entities['entityId'] == entity_id:\n",
    "                term = entities['preferredTerm']\n",
    "                linked_entities.append([id,text,term,entity_id])\n",
    "                linked_from_id.append(id)\n",
    "                linked_from_text.append(text)\n",
    "                linked_to_id.append(entity_id)\n",
    "                linked_to_text.append(term)\n",
    "\n",
    "    for k in range(len(linked_from_id)):\n",
    "      caseno.append(df['CASENO'][i])\n",
    "      noteno.append(df['index'][i])\n",
    "      date.append(df['DATE'][i])\n",
    "      desc.append(df['DESCRIPTION'][i])\n",
    "      source.append(df['RECORD_SOURCE_TABLE'][i])\n",
    "\n",
    "    related_entities = []\n",
    "    if 'relationships' in x:\n",
    "        for relations in x['relationships']:\n",
    "          related_entities.append([relations['subjectId'],relations['objectId']])\n",
    "\n",
    "\n",
    "    relationship = []\n",
    "    if len(related_entities) != 0:\n",
    "        relationship = []\n",
    "        for ids in related_entities:\n",
    "            id1 = ids[0]\n",
    "            id2 = ids[1]\n",
    "            text1 = None  # Initialize text1\n",
    "            text2 = None  # Initialize text2\n",
    "            for entity in x['entityMentions']:\n",
    "                if entity['mentionId'] == str(id1):\n",
    "                    text1 = entity['text']['content']\n",
    "                if entity['mentionId'] == str(id2):\n",
    "                    text2 = entity['text']['content']\n",
    "\n",
    "            relationship.append([id1, text1, \"related to\", id2, text2])\n",
    "            related_from_id.append(id1)\n",
    "            related_from_text.append(text1)\n",
    "            related_to_id.append(id2)\n",
    "            related_to_text.append(text2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data.update({\n",
    "              'CASE NO': caseno,\n",
    "              'NOTE NO':noteno,\n",
    "              'DATE': date,\n",
    "              'SOURCE':source,\n",
    "              'text id': linked_from_id,\n",
    "              'linked from text': linked_from_text,\n",
    "              'UMLS': linked_to_id,\n",
    "              'linked to term': linked_to_text\n",
    "              })\n",
    "\n",
    "\n",
    "\n",
    "  return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get related entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def struct_relations(df):\n",
    "  data = {}\n",
    "  caseno = []\n",
    "  noteno = []\n",
    "  date = []\n",
    "  desc = []\n",
    "  source = []\n",
    "  temp_asst = []\n",
    "  cert_asst = []\n",
    "  subject = []\n",
    "  linked_entity_id = []\n",
    "  linked_to_id = []\n",
    "  linked_from_id = []\n",
    "  linked_from_text = []\n",
    "  linked_to_text = []\n",
    "  related_entities = []\n",
    "  related_from_id = []\n",
    "  related_to_id = []\n",
    "  related_from_text = []\n",
    "  related_to_text = []\n",
    "  mention_ids = []  # List to store mention IDs\n",
    "  entity_types = []  # List to store entity types\n",
    "  texts = []  # List to store texts\n",
    "  confi = []\n",
    "  # Assuming you have already extracted the relevant data in the following lists\n",
    "  mention_ids = []  # List to store mention IDs\n",
    "  entity_types = []  # List to store entity types\n",
    "  texts = []  # List to store texts\n",
    "\n",
    "  for i in range(len(df)):\n",
    "    if isinstance(df['NER'][i], str):\n",
    "      x = ast.literal_eval(df['NER'][i])\n",
    "    else:\n",
    "      x = df['NER'][i]\n",
    "\n",
    "\n",
    "    if 'entityMentions' in x:\n",
    "        for entity in x['entityMentions']:\n",
    "            id = f\"[id - {entity['mentionId']}]\"\n",
    "            entity_type = f\"[entity-type = {entity['type']}]\"\n",
    "            text = f\"[text = {entity['text']['content']}]\"\n",
    "\n",
    "            mention_ids.append(entity['mentionId'])\n",
    "            entity_types.append(entity['type'])\n",
    "            texts.append(entity['text']['content'])\n",
    "            confi.append(entity['confidence'])\n",
    "            if 'temporalAssessment' in entity:\n",
    "              temp_asst.append(entity['temporalAssessment']['value'])\n",
    "            else:\n",
    "              temp_asst.append(None)\n",
    "            if 'certaintyAssessment' in entity:\n",
    "              cert_asst.append(entity['certaintyAssessment']['value'])\n",
    "            else:\n",
    "              cert_asst.append(None)\n",
    "\n",
    "            if 'subject' in entity:\n",
    "              subject.append(entity['subject']['value'])\n",
    "            else:\n",
    "              subject.append(None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    linked_entity_id = []\n",
    "    if 'entityMentions' in x:\n",
    "        for entity in x['entityMentions']:\n",
    "          if 'linkedEntities' in entity:\n",
    "            id = entity['mentionId']\n",
    "            text = entity['text']['content']\n",
    "            linked_id = entity['linkedEntities']\n",
    "            for ids in linked_id:\n",
    "              linked_entity_id.append([id,text,ids['entityId']])\n",
    "\n",
    "    linked_entities = []\n",
    "    if len(linked_entity_id) != 0:\n",
    "        for ids in linked_entity_id:\n",
    "          id = ids[0]\n",
    "          entity_id = ids[2]\n",
    "          text = ids[1]\n",
    "          for entities in x['entities']:\n",
    "              if entities['entityId'] == entity_id:\n",
    "                term = entities['preferredTerm']\n",
    "                linked_entities.append([id,text,term,entity_id])\n",
    "                linked_from_id.append(id)\n",
    "                linked_from_text.append(text)\n",
    "                linked_to_id.append(entity_id)\n",
    "                linked_to_text.append(term)\n",
    "\n",
    "\n",
    "\n",
    "    related_entities = []\n",
    "    if 'relationships' in x:\n",
    "        for relations in x['relationships']:\n",
    "          related_entities.append([relations['subjectId'],relations['objectId']])\n",
    "\n",
    "\n",
    "    relationship = []\n",
    "    if len(related_entities) != 0:\n",
    "        relationship = []\n",
    "        for ids in related_entities:\n",
    "            id1 = ids[0]\n",
    "            id2 = ids[1]\n",
    "            text1 = None  # Initialize text1\n",
    "            text2 = None  # Initialize text2\n",
    "            for entity in x['entityMentions']:\n",
    "                if entity['mentionId'] == str(id1):\n",
    "                    text1 = entity['text']['content']\n",
    "                if entity['mentionId'] == str(id2):\n",
    "                    text2 = entity['text']['content']\n",
    "\n",
    "            relationship.append([id1, text1, \"related to\", id2, text2])\n",
    "            related_from_id.append(id1)\n",
    "            related_from_text.append(text1)\n",
    "            related_to_id.append(id2)\n",
    "            related_to_text.append(text2)\n",
    "\n",
    "\n",
    "    for k in range(len(related_from_id)):\n",
    "      caseno.append(df['CASENO'][i])\n",
    "      noteno.append(df['index'][i])\n",
    "      date.append(df['DATE'][i])\n",
    "      desc.append(df['DESCRIPTION'][i])\n",
    "      source.append(df['RECORD_SOURCE_TABLE'][i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data.update({\n",
    "              'CASENO': caseno,\n",
    "              'NOTE NO':noteno,\n",
    "              'DATE': date,\n",
    "              'SOURCE':source,\n",
    "              'Entity_id': related_from_id,\n",
    "              'related_from': related_from_text,\n",
    "              'related_to_entity_id': related_to_id,\n",
    "              'related_to_term': related_to_text\n",
    "              })\n",
    "\n",
    "\n",
    "\n",
    "  return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_lists(data):\n",
    "    max_len = max(len(lst) for lst in data.values())\n",
    "    return {k: v + [None]*(max_len-len(v)) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 cases at a time or 1 list of case at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the DataFrame\n",
    "temp = df[df['CASENO'].isin(lists_of_cases[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['NER'] = temp['CLEAN'].apply(get_entities) #test on first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_dict_entities = pad_lists(struct_entities(temp))\n",
    "padded_dict_linked = pad_lists(struct_linked_entities(temp))\n",
    "padded_dict_relations = pad_lists(struct_relations(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_entities = pd.DataFrame(padded_dict_entities)\n",
    "final_df_linked = pd.DataFrame(padded_dict_linked)\n",
    "final_df_relations = pd.DataFrame(padded_dict_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### full dataframe in a batch of 10 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_ner = []\n",
    "count = 1\n",
    "for number in lists_of_cases:\n",
    "    count+=1\n",
    "    temp = df[df['CASENO'].isin(number)]\n",
    "    temp['NER'] = temp['CLEAN'].apply(get_entities)\n",
    "    padded_dict_entities = pad_lists(struct_entities(temp))\n",
    "    padded_dict_linked = pad_lists(struct_linked_entities(temp))\n",
    "    padded_dict_relations = pad_lists(struct_relations(temp))\n",
    "\n",
    "    final_df_entities = pd.DataFrame(padded_dict_entities)\n",
    "    final_df_linked = pd.DataFrame(padded_dict_linked)\n",
    "    final_df_relations = pd.DataFrame(padded_dict_relations)\n",
    "    \n",
    "    final_df_entities.to_csv(f\"final_df_entities_from_list_{count}.csv\",index=False)\n",
    "    final_df_linked.to_csv(f\"final_df_linked_from_list_{count}.csv\",index=False)\n",
    "    final_df_relations.to_csv(f\"final_df_relations-from_list_{count}.csv\",index=False)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
